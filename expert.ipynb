{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auto reload \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.7.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajvendetta/.pyenv/versions/3.7.16/envs/bcirl/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from snake_env_ray import SnakeEnv\n",
    "import mediapy as media\n",
    "import pygame\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "config = yaml.load(open(\"bc-irl-snake.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "env_config = config[\"env\"][\"env_settings\"][\"params\"][\"config\"]\n",
    "env_config[\"render_mode\"] = \"human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"show_images\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><img width=\"200\" height=\"200\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAACOklEQVR4nO3cMQrDMBAAwSj4/19WXhBMLC8iZqY/ULFcdWjMOV9wt/fuB/BMwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLH0vQY12f9L/9oNhYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBaJtZt3d+t8YWOREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZE4dj+Ac2Ncn53zvnf8wsYiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIi4eb9D+y6W19hY5EQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZH4AAOcDJGLJKlnAAAAAElFTkSuQmCC\"/></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "snakie = SnakeEnv(env_config)\n",
    "snakie.render_mode = \"rgb_array\"\n",
    "snakie.reset()\n",
    "media.show_image(snakie.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.6]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL4AAAC+CAYAAACLdLWdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAE+ElEQVR4nO3dQWscZRjA8Wd3GiiU2l1KKxYED9tbF3rRhlbw5BfIVWT7UfpREtBr8gG8tiW9CBIQxEWRerCWmA1isaSz62EoFSH2lXmSHef//11C2OGZl+y/w3STlxmsVqtVSDDDdS9AWgfDF5LhC8nwhWT4QjJ8IRm+kAxfSIYvpAvFR344aH+2T9qPSJnxccKM8acJQ2YJMz5LmPFlwoyd9iOOvmo/Y1z2hwhe8YVk+EIqv9XR/8/BQcTubsRiETEaRWxtRUyn615VJxh+H83nEbNZxOPHEVUVMRxGLJcRDx5E3LsXsb0dMZmse5Vr5a1O38znEXfuRDx50nxf1xEnJ83XiIj9/eb1+Xx9a+wAw++b2Szi+PhN6P9U183r9++f67K6xvD75OCgub05LfrX6jri0aPmeCjD75Pd3eaevkRVReztne16Oszw+2SxaP4jW2I4jDg6OtPldJnh98lo1Hx6U2K5jBiPz3Q5XWb4fbK19fb7+9fqujkeyvD7ZDqNuHv37ff5VdV8nn/r1vmsq4MMv292diKuXDk9/qpqXt/ePtdldY3h981k0vzyanOz+b6qIjY23vxD2NxsXof/5tY/WeijySTi4cPmc/q9vebTm/G4uacH3978neH32XTqH6Wdojz8wg8L/tVJwow/OzIjDhNmfJcwI2MTScY6En4eKe9LGe/xhWT4QjJ8IRm+kAxfSIYvJMMXkuELyfCFZPhCMnwhGb6QDF9Ihi8kwxeS4QupfCPKIuFsGXs3nifMeJow49rX7Wek7H/bT5iR8Ma8Svh5ZLwv75Ud5hVfSIYvJMMXkuELyfCFZPhCMnwhGb6QDF9Ihi8kwxeS4QvJ8IVk+EIyfCEZvpDKt0I8SzhbxkaDHxJmXE6YkeH9hM0bF9uPSHkSScZ7m/Fglo/KDvOKLyTDF5LhC8nwhWT4QjJ8IRm+kAxfSIYvJMMXkuELyfCFZPhCMnwhGb6QDF9IxRtRfn3R/mTX+7SJ5PeEGT8lzOjKRpSMJ9Vk9PF52WFe8YVk+EIyfCEZvpAMX0iGLyTDF5LhC8nwhWT4QjJ8IRm+kAxfSIYvJMMXkuELqXgjyvcJJ7v4c/sZ77QfkbOJ5JeEGVcTZmwkzDhJmHGYMCPjqSqFvOILyfCFZPhCMnwhGb6QDF9Ihi8kwxeS4QvJ8IVk+EIyfCEZvpAMX0iGLyTDF1LxRpRvz3IV/8HNhM0s139rPyNl08QoYUaVMKNOmLFImPEsYUYhr/hCMnwhGb6QDF9Ihi8kwxeS4QvJ8IVk+EIyfCEZvpAMX0iGLyTDF5LhC8nwhVS8EeWbhJO9TJhxnDDjxov2M6792H7G5fYjOvNAlIyHzDxPmHG78Div+EIyfCEZvpAMX0iGLyTDF5LhC8nwhWT4QjJ8IRm+kAxfSIYvJMMXkuELyfCFdK4bUbqyWeHdhBlXE2ZkbETJuHItE2ZkvLeHCTNuFx7nFV9Ihi8kwxeS4QvJ8IVk+EIyfCEZvpAMX0iGLyTDF5LhC8nwhWT4QjJ8IRm+kAar1WpVcuClwaD1yT5oPSHiRsKMjI0oo4QZlxJmdGUjyh8JMxYJM74oy9krvpgMX0iGLyTDF5LhC8nwhWT4QjJ8IRm+kAxfSIYvJMMXkuELyfCFZPhCMnwhFW9EkfrEK76QDF9Ihi8kwxeS4QvJ8IVk+EIyfCEZvpD+AvhbprM+8Is3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_env = SnakeEnv(env_config)\n",
    "reward_map = np.zeros((eval_env.screen_width//eval_env.block_size, eval_env.screen_height//eval_env.block_size))\n",
    "apple_pos = eval_env.reset()[0][:2]\n",
    "print(apple_pos)\n",
    "#test what you got so far by plotting a heat map of the reward using the snake only \n",
    "for x in range(eval_env.screen_width//eval_env.block_size):\n",
    "    for y in range(eval_env.screen_height//eval_env.block_size ):\n",
    "        x_grid = x * eval_env.block_size / eval_env.screen_width\n",
    "        y_grid = y * eval_env.block_size / eval_env.screen_height\n",
    " \n",
    "        reward_map[x,y] = 1.0-eval_env.normalized_distance((x_grid, y_grid), apple_pos)\n",
    "fig, ax = plt.subplots(figsize=(2, 2))  # Adjust the figsize as desired\n",
    "\n",
    "# Plot the reward map without axis and numbers\n",
    "image = ax.imshow(reward_map, cmap='hot', interpolation='nearest')\n",
    "ax.axis('off')\n",
    "\n",
    "# Plot the apple\n",
    "ax.scatter(\n",
    "    apple_pos[1] * eval_env.screen_height // eval_env.block_size,\n",
    "    apple_pos[0] * eval_env.screen_width // eval_env.block_size,\n",
    "\n",
    "    c='red',\n",
    "    s=60\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def to_grid(snakie):\n",
    "    #transform the observation into a grid \n",
    "    image = np.zeros((snakie.screen_height//snakie.block_size, snakie.screen_width//snakie.block_size),dtype=np.uint8)\n",
    "\n",
    "    #red for the apple \n",
    "    image[snakie.apple.position[0]//snakie.block_size, snakie.apple.position[1]//snakie.block_size] = 3\n",
    "\n",
    "    #green for the snake\n",
    "    for pos in snakie.snake.body:\n",
    "        image[pos[0]//snakie.block_size, pos[1]//snakie.block_size,] = 1\n",
    "    #blue for the head\n",
    "    image[snakie.snake.head[0]//snakie.block_size, snakie.snake.head[1]//snakie.block_size,] = 2\n",
    "    return image \n",
    "\n",
    "def find_shortest_path(grid, player_location, apple_position):\n",
    "    rows, cols = len(grid), len(grid[0])\n",
    "    queue = deque()\n",
    "    visited = set()\n",
    "    queue.append(player_location)\n",
    "    visited.add(player_location)\n",
    "    directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "    path = {}\n",
    "\n",
    "    while queue:\n",
    "        current_cell = queue.popleft()\n",
    "        if current_cell == apple_position:\n",
    "            break\n",
    "\n",
    "        for direction in directions:\n",
    "            next_row = current_cell[0] + direction[0] \n",
    "            next_col = current_cell[1] + direction[1]\n",
    "            next_cell = (next_row, next_col)\n",
    "            print(player_location,next_cell)\n",
    "            if 0 <= next_row < rows and 0 <= next_col < cols and grid[next_row][next_col] != 1 and next_cell not in visited:\n",
    "                queue.append(next_cell)\n",
    "                visited.add(next_cell)\n",
    "                path[next_cell] = current_cell\n",
    "    print(path)\n",
    "    if apple_position not in path:\n",
    "        return None\n",
    "\n",
    "    # Reconstruct the path\n",
    "    current_cell = apple_position\n",
    "    while current_cell != player_location:\n",
    "        parent_cell = path[current_cell]\n",
    "        if (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (1, 0):\n",
    "            action = 0\n",
    "        elif (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (-1, 0):\n",
    "            action = 1\n",
    "        elif (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (0, 1):\n",
    "            action = 2\n",
    "        else:\n",
    "            action = 3\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def astar(start, goal, walls):\n",
    "    \"\"\"\n",
    "    A* algorithm implementation to find the shortest path from start to goal\n",
    "    on a grid with walls represented as 1s.\n",
    "    \"\"\"\n",
    "    # Define the heuristic function as the Manhattan distance\n",
    "    def heuristic(node):\n",
    "        return abs(node[0] - goal[0]) + abs(node[1] - goal[1])\n",
    "    \n",
    "    # Initialize the open and closed sets\n",
    "    open_set = [(0, start)]\n",
    "    closed_set = set()\n",
    "    \n",
    "    # Initialize the g score for the start node\n",
    "    g_score = {start: 0}\n",
    "    \n",
    "    # Initialize the parent dictionary to keep track of the path\n",
    "    parent = {}\n",
    "    \n",
    "    while open_set:\n",
    "        # Get the node with the lowest f score from the open set\n",
    "        current = heapq.heappop(open_set)[1]\n",
    "        \n",
    "        # If we've reached the goal, reconstruct the path and return it\n",
    "        if current == goal:\n",
    "            path = []\n",
    "            while current in parent:\n",
    "                path.append(current)\n",
    "                current = parent[current]\n",
    "            path.reverse()\n",
    "            return path\n",
    "        \n",
    "        # Add the current node to the closed set\n",
    "        closed_set.add(current)\n",
    "        \n",
    "        # Check the neighbors of the current node\n",
    "        for neighbor in [(current[0]+1, current[1]), (current[0]-1, current[1]), (current[0], current[1]+1), (current[0], current[1]-1)]:\n",
    "            # Skip neighbors that are walls or already in the closed set\n",
    "            if neighbor in walls or neighbor in closed_set:\n",
    "                continue\n",
    "            \n",
    "            # Calculate the tentative g score for the neighbor\n",
    "            tentative_g_score = g_score[current] + 1\n",
    "            \n",
    "            # If the neighbor is not in the open set, add it and calculate its f score\n",
    "            if neighbor not in [node[1] for node in open_set]:\n",
    "                heapq.heappush(open_set, (tentative_g_score + heuristic(neighbor), neighbor))\n",
    "            # If the neighbor is already in the open set, update its g score if the new score is lower\n",
    "            elif tentative_g_score < g_score[neighbor]:\n",
    "                if((g_score[neighbor] + heuristic(neighbor), neighbor) in open_set):\n",
    "                        \n",
    "                    open_set.remove((g_score[neighbor] + heuristic(neighbor), neighbor))\n",
    "                    heapq.heappush(open_set, (tentative_g_score + heuristic(neighbor), neighbor))\n",
    "            \n",
    "            # Update the parent and g score dictionaries\n",
    "            parent[neighbor] = current\n",
    "            g_score[neighbor] = tentative_g_score\n",
    "            \n",
    "    # If we've exhausted all possible paths and haven't found the goal, return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (2, 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the grid and the player and apple positions\n",
    "grid = [[1, 1, 1, 1],\n",
    "        [1, 0, 0, 1],\n",
    "        [1, 1, 3, 1],\n",
    "        [1, 1, 1, 1]]\n",
    "player_pos = (1, 1)\n",
    "apple_pos = (2, 2)\n",
    "\n",
    "# Find the shortest path using the A* algorithm\n",
    "walls = [(i, j) for i in range(len(grid)) for j in range(len(grid[0])) if grid[i][j] == 1]\n",
    "\n",
    "astar(player_pos, apple_pos, walls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'render_mode': 'human',\n",
       " 'screen_width': 200,\n",
       " 'screen_height': 200,\n",
       " 'block_size': 20,\n",
       " 'max_hunger_coef': 1,\n",
       " 'max_steps_coef': 30}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config[\"render_mode\"] = \"human\"\n",
    "snakie = SnakeEnv(env_config)\n",
    "frames = []\n",
    "# Find shortest path to apple \n",
    "obs = snakie.reset()\n",
    "\n",
    "done = False\n",
    "while not done : \n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            done = True\n",
    "    \n",
    "    grid = to_grid(snakie)\n",
    "    walls =[(x//snakie.block_size,y//snakie.block_size) for (x,y) in snakie.snake.body[:-1]]\n",
    "    current_cell = (snakie.snake.head[0]//snakie.block_size,snakie.snake.head[1]//snakie.block_size)\n",
    "\n",
    "\n",
    "    path =  astar(current_cell, (snakie.apple.position[0]//snakie.block_size,snakie.apple.position[1]//snakie.block_size), walls)\n",
    "    if(path is not None):\n",
    "        next_cell = path[0]\n",
    "    parent_cell = current_cell\n",
    "    current_cell = next_cell \n",
    "\n",
    "    if (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (1, 0):\n",
    "        action = 2\n",
    "    elif (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (-1, 0):\n",
    "        action = 3\n",
    "    elif (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (0, 1):\n",
    "        action = 0\n",
    "    else:\n",
    "        action = 1\n",
    "    # action = find_shortest_path(grid, (snakie.snake.head[0]//snakie.block_size,snakie.snake.head[1]//snakie.block_size), (snakie.apple.position[0]//snakie.block_size,snakie.apple.position[1]//snakie.block_size))\n",
    "    prob_action = np.zeros(4)\n",
    "    prob_action[action] = 1\n",
    "    \n",
    "    \n",
    "    obs, reward, done,  _ , info = snakie.step(prob_action)\n",
    "    snakie.render(\"human\")\n",
    "    # frames.append(snakie.render(\"rgb_array\"))\n",
    "    pygame.time.wait(5)\n",
    "#media.show_video(frames, fps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_exp = 4\n",
    "expert_exp = {\"reward\": [], \"action\": [], \"observation\": [], \"terminal\": [], \"next_observation\": []}\n",
    "snakie = SnakeEnv({**env_config})\n",
    "for experience in range(n_exp):\n",
    "    #run forever and take actions from keyboard and collect data about the reward\n",
    "\n",
    "    expert_exp[\"observation\"].append(snakie.reset()[0])\n",
    "    done = False\n",
    "    action = 0 \n",
    "    while not done:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "        walls =[(x//snakie.block_size,y//snakie.block_size) for (x,y) in snakie.snake.body[:-1]]\n",
    "        current_cell = (snakie.snake.head[0]//snakie.block_size,snakie.snake.head[1]//snakie.block_size)\n",
    "\n",
    "\n",
    "        path =  astar(current_cell, (snakie.apple.position[0]//snakie.block_size,snakie.apple.position[1]//snakie.block_size), walls)\n",
    "        if(path is not None):\n",
    "            next_cell = path[0]\n",
    "        parent_cell = current_cell\n",
    "        current_cell = next_cell \n",
    "\n",
    "        if (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (1, 0):\n",
    "            action = 2\n",
    "        elif (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (-1, 0):\n",
    "            action = 3\n",
    "        elif (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (0, 1):\n",
    "            action = 0\n",
    "        else:\n",
    "            action = 1\n",
    "\n",
    "        probs = [0,0,0,0]\n",
    "        probs[action] = 1\n",
    "        obs,reward,done,_,info= snakie.step(probs)\n",
    "   \n",
    "        expert_exp[\"reward\"].append(reward)\n",
    "        expert_exp[\"action\"].append(probs)\n",
    "        expert_exp[\"observation\"].append(obs)\n",
    "        expert_exp[\"terminal\"].append(done)\n",
    "        expert_exp[\"next_observation\"].append(obs)\n",
    "        # print(expert_exp[\"action\"][-1], expert_exp[\"reward\"][-1], expert_exp[\"terminal\"][-1])\n",
    "        \n",
    "        snakie.render(\"human\")\n",
    "        pygame.time.wait(10)\n",
    "    expert_exp[\"observation\"] = expert_exp[\"observation\"][:-1]\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_exp = 4\n",
    "# expert_exp = {\"reward\": [], \"action\": [], \"observation\": [], \"terminal\": [], \"next_observation\": []}\n",
    "# snakie = SnakeEnv({**env_config})\n",
    "# pygame.time.wait(1000)\n",
    "# for experience in range(n_exp):\n",
    "#     #run forever and take actions from keyboard and collect data about the reward\n",
    "\n",
    "#     expert_exp[\"observation\"].append(snakie.reset()[0])\n",
    "#     done = False\n",
    "#     action = 0 \n",
    "#     while not done:\n",
    "#         for event in pygame.event.get():\n",
    "#             if event.type == pygame.QUIT:\n",
    "#                 pygame.quit()\n",
    "#             if event.type == pygame.KEYDOWN:\n",
    "#                 if event.key == pygame.K_LEFT:\n",
    "#                     action = 2\n",
    "#                 elif event.key == pygame.K_RIGHT:\n",
    "#                     action = 3\n",
    "#                 elif event.key == pygame.K_UP:\n",
    "#                     action = 0\n",
    "#                 elif event.key == pygame.K_DOWN:\n",
    "#                     action = 1\n",
    "\n",
    "#         probs = [0,0,0,0]\n",
    "#         probs[action] = 1\n",
    "#         obs,reward,done,info= snakie.step(probs)\n",
    "   \n",
    "#         expert_exp[\"reward\"].append(reward)\n",
    "#         expert_exp[\"action\"].append(probs)\n",
    "#         expert_exp[\"observation\"].append(obs)\n",
    "#         expert_exp[\"terminal\"].append(done)\n",
    "#         expert_exp[\"next_observation\"].append(obs)\n",
    "#         # print(expert_exp[\"action\"][-1], expert_exp[\"reward\"][-1], expert_exp[\"terminal\"][-1])\n",
    "        \n",
    "#         snakie.render(\"human\")\n",
    "#         pygame.time.wait(50)\n",
    "#     expert_exp[\"observation\"] = expert_exp[\"observation\"][:-1]\n",
    "# pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n",
      "492\n"
     ]
    }
   ],
   "source": [
    "print(len(expert_exp[\"next_observation\"]))\n",
    "print(len(expert_exp[\"observation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations =[obs[0].tolist() if isinstance(obs, tuple) else obs.tolist() for obs in expert_exp[\"observation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_observation = [obs[0].tolist() if isinstance(obs, tuple) else obs.tolist() for obs in expert_exp[\"next_observation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = expert_exp[\"action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dones = expert_exp[\"terminal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = expert_exp[\"reward\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobejsoned = {\"observations\": observations, \"actions\": actions, \"terminals\": dones, \"next_observations\": new_observation , \"rewards\": rewards}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"expert_data.json\", \"w\") as f:\n",
    "    json.dump(tobejsoned, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tobejsoned[\"terminals\"].count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
