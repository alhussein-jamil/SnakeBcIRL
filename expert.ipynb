{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auto reload \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.7.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajvendetta/.pyenv/versions/3.7.16/envs/bcirl/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from snake_env_ray import SnakeEnv\n",
    "import mediapy as media\n",
    "import pygame\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "config = yaml.load(open(\"bc-irl-snake.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "env_config = config[\"env\"][\"env_settings\"][\"params\"][\"config\"]\n",
    "env_config[\"render_mode\"] = \"human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"show_images\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><img width=\"200\" height=\"200\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAACNElEQVR4nO3cQQqEMBAAwc3i/78cvyBiK9GqeyCHZk6TjDnnD672f/oCvJOwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi8T29AVuN8b5s94HHGZikRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkfjezru99VuYWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCS+t/O+oBW/pjexSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSNh5X8CKX9ObWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkdopuDJEpeX7hAAAAAElFTkSuQmCC\"/></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "snakie = SnakeEnv(env_config)\n",
    "snakie.render_mode = \"rgb_array\"\n",
    "snakie.reset()\n",
    "media.show_image(snakie.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9 0.6]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL4AAAC+CAYAAACLdLWdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAE+UlEQVR4nO3dT2scBRjH8Wd3G2gTWlNC2qAGiiRaxCAUi8W+BG+5eqgn+y788zLqqYJe0zehpaXFS09q6iWXSAlGpFUou+thKBUhdGB/yY7z/X4uJWx4ZqDfTqebfTqD6XQ6LQlmOO8TkObB8IVk+EIyfCEZvpAMX0iGLyTDF5LhC+lU229cGgxmPtilmSdUvR6YcTEwYzkwYykwI3HlmgRmPA3MOAzM+LblBxG84gvJ8IVk+EIyfCEZvpAMX0iGLyTDF5LhC8nwhWT4QjJ8IRm+kAxfSIYvJMMXUutFlCuBg70VmHEpMCOxiLISmHE2MKMriyh/BmYcBGa05RVfSIYvJMMXkuELyfCFZPhCMnwhGb6QDF9Ihi8kwxeS4QvJ8IVk+EIyfCEZvpBaL6K8HzjY5cCMxDJL4qkqq4EZiUWUhcCM54EZiUWUJ4EZbXnFF5LhC8nwhWT4QjJ8IRm+kAxfSIYvJMMXkuELyfCFZPhCMnwhGb6QDF9Ihi+kE11EeTcwYzMw48JiYEjisSrLgRmj2UecGc8+49zh7DPe+G32GW15xReS4QvJ8IVk+EIyfCEZvpAMX0iGLyTDF5LhC8nwhWT4QjJ8IRm+kAxfSIYvpNaLKIklkq3AjHNvBoYkHquyHpixEpjRlUeiHARm7AVmtOQVX0iGLyTDF5LhC8nwhWT4QjJ8IRm+kAxfSIYvJMMXkuELyfCFZPhCMnwhGb6QWi+iJJ5EElkiSTya5XJgRmKZZTUw43Rgxt+BGU8CM34NzGjJK76QDF9Ihi8kwxeS4QvJ8IVk+EIyfCEZvpAMX0iGLyTDF5LhC8nwhWT4QjJ8IbVeRLmwGDhaYnkjsUSSWGZ5JzAj8VSVriyiJJ5mcjYwoyWv+EIyfCEZvpAMX0iGLyTDF5LhC8nwhWT4QjJ8IRm+kAxfSIYvJMMXkuELyfCF1HoRpS4GjpZYvEgssySWSK4EZpxKDFkJzDiYfcTqj7PPOEFe8YVk+EIyfCEZvpAMX0iGLyTDF5LhC8nwhWT4QjJ8IRm+kAxfSIYvJMMXkuELqf0iynLgaImdidXAjMRCTGSJ5OPAjMRWzU+zj2hf0tHWT26ZxSu+kAxfSIm/oNRVj/aqdh5UHT6rWl6s2r5atZW4z/v/M/w+2t2vunGr6u4vVaNh1XBQNZlWfblTdX2z6vbNqo21eZ/lXHmr0ze7+1UfflF1/3Hz9XhS9Xzc/FpVde9x8/ru/vzOsQMMv29u3Kr646+Xof/XeNK8/unXJ3teHWP4ffJor7m9OSr6F8aTqh9+br4fyvD7ZOdBc0/fxmhYdefh8Z5Phxl+nxw+a/4h28ZwUPX70+M9nw4z/D5ZXmzevWljMq06v3S859Nhht8n21dffX//wnhStf3B8Z5Phxl+n2ytV320+er7/NGw6vrbVe9xf5hl+H3zzc2q184cHf9o2Lx++7OTPa+OMfy+2Viruv9V1bWN5uvRsGph9PIPwrWN5nX4T279yEIfbaxVff958z79nYfNuzfnl5p7evDtzb8Zfp9trfuhtCO0D38UONpCYMbpjsyIbNUklkg+Ccz4LjDj3uwjIr8v7XiPLyTDF5LhC8nwhWT4QjJ8IRm+kAxfSIYvJMMXkuELyfCFZPhCMnwhGb6QDF9Ig+l02vI/YpH6wyu+kAxfSIYvJMMXkuELyfCFZPhCMnwhGb6Q/gGgx32KRwmlkQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_env = SnakeEnv(env_config)\n",
    "reward_map = np.zeros((eval_env.screen_width//eval_env.block_size, eval_env.screen_height//eval_env.block_size))\n",
    "apple_pos = eval_env.reset()[0][:2]\n",
    "print(apple_pos)\n",
    "#test what you got so far by plotting a heat map of the reward using the snake only \n",
    "for x in range(eval_env.screen_width//eval_env.block_size):\n",
    "    for y in range(eval_env.screen_height//eval_env.block_size ):\n",
    "        x_grid = x * eval_env.block_size / eval_env.screen_width\n",
    "        y_grid = y * eval_env.block_size / eval_env.screen_height\n",
    " \n",
    "        reward_map[x,y] = 1.0-eval_env.normalized_distance((x_grid, y_grid), apple_pos)\n",
    "fig, ax = plt.subplots(figsize=(2, 2))  # Adjust the figsize as desired\n",
    "\n",
    "# Plot the reward map without axis and numbers\n",
    "image = ax.imshow(reward_map, cmap='hot', interpolation='nearest')\n",
    "ax.axis('off')\n",
    "\n",
    "# Plot the apple\n",
    "ax.scatter(\n",
    "    apple_pos[1] * eval_env.screen_height // eval_env.block_size,\n",
    "    apple_pos[0] * eval_env.screen_width // eval_env.block_size,\n",
    "\n",
    "    c='red',\n",
    "    s=60\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def to_grid(snakie):\n",
    "    #transform the observation into a grid \n",
    "    image = np.zeros((snakie.screen_height//snakie.block_size, snakie.screen_width//snakie.block_size),dtype=np.uint8)\n",
    "\n",
    "    #red for the apple \n",
    "    image[snakie.apple.position[0]//snakie.block_size, snakie.apple.position[1]//snakie.block_size] = 3\n",
    "\n",
    "    #green for the snake\n",
    "    for pos in snakie.snake.body:\n",
    "        image[pos[0]//snakie.block_size, pos[1]//snakie.block_size,] = 1\n",
    "    #blue for the head\n",
    "    image[snakie.snake.head[0]//snakie.block_size, snakie.snake.head[1]//snakie.block_size,] = 2\n",
    "    return image \n",
    "\n",
    "def find_shortest_path(grid, player_location, apple_position):\n",
    "    rows, cols = len(grid), len(grid[0])\n",
    "    queue = deque()\n",
    "    visited = set()\n",
    "    queue.append(player_location)\n",
    "    visited.add(player_location)\n",
    "    directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "    path = {}\n",
    "\n",
    "    while queue:\n",
    "        current_cell = queue.popleft()\n",
    "        if current_cell == apple_position:\n",
    "            break\n",
    "\n",
    "        for direction in directions:\n",
    "            next_row = current_cell[0] + direction[0] \n",
    "            next_col = current_cell[1] + direction[1]\n",
    "            next_cell = (next_row, next_col)\n",
    "            print(player_location,next_cell)\n",
    "            if 0 <= next_row < rows and 0 <= next_col < cols and grid[next_row][next_col] != 1 and next_cell not in visited:\n",
    "                queue.append(next_cell)\n",
    "                visited.add(next_cell)\n",
    "                path[next_cell] = current_cell\n",
    "    print(path)\n",
    "    if apple_position not in path:\n",
    "        return None\n",
    "\n",
    "    # Reconstruct the path\n",
    "    current_cell = apple_position\n",
    "    while current_cell != player_location:\n",
    "        parent_cell = path[current_cell]\n",
    "        if (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (1, 0):\n",
    "            action = 0\n",
    "        elif (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (-1, 0):\n",
    "            action = 1\n",
    "        elif (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (0, 1):\n",
    "            action = 2\n",
    "        else:\n",
    "            action = 3\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def astar(start, goal, walls):\n",
    "    \"\"\"\n",
    "    A* algorithm implementation to find the shortest path from start to goal\n",
    "    on a grid with walls represented as 1s.\n",
    "    \"\"\"\n",
    "    # Define the heuristic function as the Manhattan distance\n",
    "    def heuristic(node):\n",
    "        return abs(node[0] - goal[0]) + abs(node[1] - goal[1])\n",
    "    \n",
    "    # Initialize the open and closed sets\n",
    "    open_set = [(0, start)]\n",
    "    closed_set = set()\n",
    "    \n",
    "    # Initialize the g score for the start node\n",
    "    g_score = {start: 0}\n",
    "    \n",
    "    # Initialize the parent dictionary to keep track of the path\n",
    "    parent = {}\n",
    "    \n",
    "    while open_set:\n",
    "        # Get the node with the lowest f score from the open set\n",
    "        current = heapq.heappop(open_set)[1]\n",
    "        \n",
    "        # If we've reached the goal, reconstruct the path and return it\n",
    "        if current == goal:\n",
    "            path = []\n",
    "            while current in parent:\n",
    "                path.append(current)\n",
    "                current = parent[current]\n",
    "            path.reverse()\n",
    "            return path\n",
    "        \n",
    "        # Add the current node to the closed set\n",
    "        closed_set.add(current)\n",
    "        \n",
    "        # Check the neighbors of the current node\n",
    "        for neighbor in [(current[0]+1, current[1]), (current[0]-1, current[1]), (current[0], current[1]+1), (current[0], current[1]-1)]:\n",
    "            # Skip neighbors that are walls or already in the closed set\n",
    "            if neighbor in walls or neighbor in closed_set:\n",
    "                continue\n",
    "            \n",
    "            # Calculate the tentative g score for the neighbor\n",
    "            tentative_g_score = g_score[current] + 1\n",
    "            \n",
    "            # If the neighbor is not in the open set, add it and calculate its f score\n",
    "            if neighbor not in [node[1] for node in open_set]:\n",
    "                heapq.heappush(open_set, (tentative_g_score + heuristic(neighbor), neighbor))\n",
    "            # If the neighbor is already in the open set, update its g score if the new score is lower\n",
    "            elif tentative_g_score < g_score[neighbor]:\n",
    "                if((g_score[neighbor] + heuristic(neighbor), neighbor) in open_set):\n",
    "                        \n",
    "                    open_set.remove((g_score[neighbor] + heuristic(neighbor), neighbor))\n",
    "                    heapq.heappush(open_set, (tentative_g_score + heuristic(neighbor), neighbor))\n",
    "            \n",
    "            # Update the parent and g score dictionaries\n",
    "            parent[neighbor] = current\n",
    "            g_score[neighbor] = tentative_g_score\n",
    "            \n",
    "    # If we've exhausted all possible paths and haven't found the goal, return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (2, 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the grid and the player and apple positions\n",
    "grid = [[1, 1, 1, 1],\n",
    "        [1, 0, 0, 1],\n",
    "        [1, 1, 3, 1],\n",
    "        [1, 1, 1, 1]]\n",
    "player_pos = (1, 1)\n",
    "apple_pos = (2, 2)\n",
    "\n",
    "# Find the shortest path using the A* algorithm\n",
    "walls = [(i, j) for i in range(len(grid)) for j in range(len(grid[0])) if grid[i][j] == 1]\n",
    "\n",
    "astar(player_pos, apple_pos, walls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'render_mode': 'human',\n",
       " 'screen_width': 200,\n",
       " 'screen_height': 200,\n",
       " 'block_size': 20,\n",
       " 'max_hunger_coef': 1,\n",
       " 'max_steps_coef': 30}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config[\"render_mode\"] = \"human\"\n",
    "snakie = SnakeEnv(env_config)\n",
    "frames = []\n",
    "# Find shortest path to apple \n",
    "obs = snakie.reset()\n",
    "\n",
    "done = False\n",
    "while not done : \n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            done = True\n",
    "    \n",
    "    grid = to_grid(snakie)\n",
    "    walls =[(x//snakie.block_size,y//snakie.block_size) for (x,y) in snakie.snake.body[:-1]]\n",
    "    current_cell = (snakie.snake.head[0]//snakie.block_size,snakie.snake.head[1]//snakie.block_size)\n",
    "\n",
    "\n",
    "    path =  astar(current_cell, (snakie.apple.position[0]//snakie.block_size,snakie.apple.position[1]//snakie.block_size), walls)\n",
    "    if(path is not None):\n",
    "        next_cell = path[0]\n",
    "    parent_cell = current_cell\n",
    "    current_cell = next_cell \n",
    "\n",
    "    if (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (1, 0):\n",
    "        action = 2\n",
    "    elif (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (-1, 0):\n",
    "        action = 3\n",
    "    elif (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (0, 1):\n",
    "        action = 0\n",
    "    else:\n",
    "        action = 1\n",
    "    # action = find_shortest_path(grid, (snakie.snake.head[0]//snakie.block_size,snakie.snake.head[1]//snakie.block_size), (snakie.apple.position[0]//snakie.block_size,snakie.apple.position[1]//snakie.block_size))\n",
    "    prob_action = np.zeros(4)\n",
    "    prob_action[action] = 1\n",
    "    \n",
    "    \n",
    "    obs, reward, done,  _ , info = snakie.step(prob_action)\n",
    "    snakie.render(\"human\")\n",
    "    # frames.append(snakie.render(\"rgb_array\"))\n",
    "    pygame.time.wait(5)\n",
    "#media.show_video(frames, fps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_exp = 4\n",
    "expert_exp = {\"reward\": [], \"action\": [], \"observation\": [], \"terminal\": [], \"next_observation\": []}\n",
    "snakie = SnakeEnv({**env_config})\n",
    "for experience in range(n_exp):\n",
    "    #run forever and take actions from keyboard and collect data about the reward\n",
    "\n",
    "    expert_exp[\"observation\"].append(snakie.reset()[0])\n",
    "    done = False\n",
    "    action = 0 \n",
    "    while not done:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "        walls =[(x//snakie.block_size,y//snakie.block_size) for (x,y) in snakie.snake.body[:-1]]\n",
    "        current_cell = (snakie.snake.head[0]//snakie.block_size,snakie.snake.head[1]//snakie.block_size)\n",
    "\n",
    "\n",
    "        path =  astar(current_cell, (snakie.apple.position[0]//snakie.block_size,snakie.apple.position[1]//snakie.block_size), walls)\n",
    "        if(path is not None):\n",
    "            next_cell = path[0]\n",
    "        parent_cell = current_cell\n",
    "        current_cell = next_cell \n",
    "\n",
    "        if (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (1, 0):\n",
    "            action = 2\n",
    "        elif (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (-1, 0):\n",
    "            action = 3\n",
    "        elif (parent_cell[0] - current_cell[0], parent_cell[1] - current_cell[1]) == (0, 1):\n",
    "            action = 0\n",
    "        else:\n",
    "            action = 1\n",
    "\n",
    "        probs = [0,0,0,0]\n",
    "        probs[action] = 1\n",
    "        obs,reward,done,_,info= snakie.step(probs)\n",
    "   \n",
    "        expert_exp[\"reward\"].append(reward)\n",
    "        expert_exp[\"action\"].append(probs)\n",
    "        expert_exp[\"observation\"].append(obs)\n",
    "        expert_exp[\"terminal\"].append(done)\n",
    "        expert_exp[\"next_observation\"].append(obs)\n",
    "        # print(expert_exp[\"action\"][-1], expert_exp[\"reward\"][-1], expert_exp[\"terminal\"][-1])\n",
    "        \n",
    "        snakie.render(\"human\")\n",
    "        pygame.time.wait(10)\n",
    "    expert_exp[\"observation\"] = expert_exp[\"observation\"][:-1]\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_exp = 4\n",
    "# expert_exp = {\"reward\": [], \"action\": [], \"observation\": [], \"terminal\": [], \"next_observation\": []}\n",
    "# snakie = SnakeEnv({**env_config})\n",
    "# pygame.time.wait(1000)\n",
    "# for experience in range(n_exp):\n",
    "#     #run forever and take actions from keyboard and collect data about the reward\n",
    "\n",
    "#     expert_exp[\"observation\"].append(snakie.reset()[0])\n",
    "#     done = False\n",
    "#     action = 0 \n",
    "#     while not done:\n",
    "#         for event in pygame.event.get():\n",
    "#             if event.type == pygame.QUIT:\n",
    "#                 pygame.quit()\n",
    "#             if event.type == pygame.KEYDOWN:\n",
    "#                 if event.key == pygame.K_LEFT:\n",
    "#                     action = 2\n",
    "#                 elif event.key == pygame.K_RIGHT:\n",
    "#                     action = 3\n",
    "#                 elif event.key == pygame.K_UP:\n",
    "#                     action = 0\n",
    "#                 elif event.key == pygame.K_DOWN:\n",
    "#                     action = 1\n",
    "\n",
    "#         probs = [0,0,0,0]\n",
    "#         probs[action] = 1\n",
    "#         obs,reward,done,info= snakie.step(probs)\n",
    "   \n",
    "#         expert_exp[\"reward\"].append(reward)\n",
    "#         expert_exp[\"action\"].append(probs)\n",
    "#         expert_exp[\"observation\"].append(obs)\n",
    "#         expert_exp[\"terminal\"].append(done)\n",
    "#         expert_exp[\"next_observation\"].append(obs)\n",
    "#         # print(expert_exp[\"action\"][-1], expert_exp[\"reward\"][-1], expert_exp[\"terminal\"][-1])\n",
    "        \n",
    "#         snakie.render(\"human\")\n",
    "#         pygame.time.wait(50)\n",
    "#     expert_exp[\"observation\"] = expert_exp[\"observation\"][:-1]\n",
    "# pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajvendetta/.pyenv/versions/3.7.16/envs/bcirl/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the reward collected by the expert as a heat map \n",
    "\n",
    "heat_map = np.zeros((snakie.screen_height//snakie.block_size, snakie.screen_width//snakie.block_size))\n",
    "counts = np.zeros((snakie.screen_height//snakie.block_size, snakie.screen_width//snakie.block_size))\n",
    "for i in range(len(expert_exp[\"observation\"])):\n",
    "    [x,y] = expert_exp[\"observation\"][i][2:4]\n",
    "    (x,y) = int(x*snakie.screen_width / snakie.block_size),int(y * snakie.screen_height / snakie.block_size)\n",
    "    heat_map[x,y] += expert_exp[\"reward\"][i]\n",
    "    counts[x,y] += 1\n",
    "\n",
    "heat_map = heat_map/counts\n",
    "plt.imshow(heat_map, cmap='hot', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n",
      "212\n"
     ]
    }
   ],
   "source": [
    "print(len(expert_exp[\"next_observation\"]))\n",
    "print(len(expert_exp[\"observation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations =[obs[0].tolist() if isinstance(obs, tuple) else obs.tolist() for obs in expert_exp[\"observation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_observation = [obs[0].tolist() if isinstance(obs, tuple) else obs.tolist() for obs in expert_exp[\"next_observation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = expert_exp[\"action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dones = expert_exp[\"terminal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = expert_exp[\"reward\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobejsoned = {\"observations\": observations, \"actions\": actions, \"terminals\": dones, \"next_observations\": new_observation , \"rewards\": rewards}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"expert_data.json\", \"w\") as f:\n",
    "    json.dump(tobejsoned, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tobejsoned[\"terminals\"].count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
