{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import random\n",
    "from typing import Dict,List\n",
    "\n",
    "import gym.spaces as spaces\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "from hydra.utils import instantiate as hydra_instantiate\n",
    "from omegaconf import DictConfig\n",
    "from rl_utils.envs import create_vectorized_envs\n",
    "from rl_utils.logging import Logger\n",
    "from tensordict.tensordict import TensorDict\n",
    "from torchrl.envs.utils import step_mdp\n",
    "from typing import Tuple\n",
    "from imitation_learning.common.evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snake_env import SnakeEnv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "cfg = yaml.load(open(\"bc-irl-snake.yaml\", 'r'), Loader=yaml.SafeLoader)\n",
    "cfg = DictConfig(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    \"\"\"\n",
    "    Sets the seed for numpy, python random, and pytorch.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import Env\n",
    "class vectorized_env():\n",
    "    def __init__(self, envs : List[Env]):\n",
    "        self.envs = envs\n",
    "        self.num_envs = len(self.envs)\n",
    "        self.observation_space = self.envs[0].observation_space\n",
    "        self.action_space = self.envs[0].action_space\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        return torch.tensor([env.reset()[0].tolist() for env in self.envs],dtype=torch.float32)\n",
    "    \n",
    "    def step(self, action) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, List[Dict]]:\n",
    "        steps = [env.step(action[i]) for i,env in enumerate(self.envs)]\n",
    "        return_value = (torch.tensor([step[0].tolist() for step in steps],dtype=torch.float32),\n",
    "                torch.tensor([step[1] for step in steps],dtype=torch.float32),\n",
    "                torch.tensor([step[2] for step in steps],dtype=torch.bool),\n",
    "                [step[3] for step in steps])\n",
    "        return return_value\n",
    "    \n",
    "    def render(self, mode = \"rgb_array\"):\n",
    "        if(self.envs[0].render_mode == \"rgb_array\"):\n",
    "            return [env.render(mode) for env in self.envs]\n",
    "        else:\n",
    "            self.envs[0].render(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_steps 100\n",
      "Assigning full prefix 62-3-umQn0d\n",
      "400 100 16\n",
      "observations\n",
      "\t torch.Size([295, 202])\n",
      "actions\n",
      "\t torch.Size([295, 4])\n",
      "terminals\n",
      "\t torch.Size([295])\n",
      "next_observations\n",
      "\t torch.Size([295, 202])\n",
      "rewards\n",
      "\t torch.Size([295])\n",
      "infos\n",
      "\t 295\n"
     ]
    }
   ],
   "source": [
    "set_seed(cfg.seed)\n",
    "\n",
    "device = torch.device(cfg.device)\n",
    "\n",
    "# Setup the environments\n",
    "set_env_settings = {\n",
    "    k: hydra_instantiate(v) if isinstance(v, DictConfig) else v\n",
    "    for k, v in cfg.env.env_settings.items()\n",
    "}\n",
    "envs = vectorized_env([SnakeEnv(cfg.env.env_settings.params.config) for _ in range(cfg.num_envs)])\n",
    "\n",
    "steps_per_update = cfg.num_steps * cfg.num_envs\n",
    "print(\"num_steps\" , cfg.num_steps)\n",
    "num_updates = int(cfg.num_env_steps) // steps_per_update\n",
    "\n",
    "# Set dynamic variables in the config.\n",
    "cfg.obs_shape = envs.observation_space.shape\n",
    "cfg.action_dim = envs.action_space.shape[0]\n",
    "cfg.action_is_discrete = isinstance(cfg.action_dim, spaces.Discrete)\n",
    "cfg.total_num_updates = num_updates\n",
    "\n",
    "logger: Logger = hydra_instantiate(cfg.logger, full_cfg=cfg)\n",
    "policy = hydra_instantiate(cfg.policy)\n",
    "policy = policy.to(device)\n",
    "updater = hydra_instantiate(cfg.policy_updater, policy=policy, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_update = 0\n",
    "if cfg.load_checkpoint is not None:\n",
    "    # Load a checkpoint for the policy/reward. Also potentially resume\n",
    "    # training.\n",
    "    ckpt = torch.load(cfg.load_checkpoint)\n",
    "    updater.load_state_dict(ckpt[\"updater\"], should_load_opt=cfg.resume_training)\n",
    "    if cfg.load_policy:\n",
    "        policy.load_state_dict(ckpt[\"policy\"])\n",
    "    if cfg.resume_training:\n",
    "        start_update = ckpt[\"update_i\"] + 1\n",
    "\n",
    "eval_info = {\"run_name\": logger.run_name}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updates 0, Steps 1600, FPS -15818\n",
      "Over the last 10 episodes:\n",
      "    - episode.reward: 0.5635820891762349\n",
      "    - episode.score: 0.0\n",
      "    - episode.distance_to_goal: 0.4364179108237651\n",
      "    - inferred_episode_reward: 4.370217645168305\n",
      "    - value_loss: 4.662073421478271\n",
      "    - action_loss: -0.005425080336863175\n",
      "    - dist_entropy: 5.6787519454956055\n",
      "    - irl_loss: 0.404005229473114\n",
      "[tensor(0.1000), tensor(0.3000), 0.0, 0.0]\n",
      "[tensor(0.1000), tensor(0.3000), 0.0, 0.1]\n",
      "[tensor(0.1000), tensor(0.3000), 0.0, 0.2]\n",
      "[tensor(0.1000), tensor(0.3000), 0.0, 0.3]\n",
      "[tensor(0.1000), tensor(0.3000), 0.0, 0.4]\n",
      "[tensor(0.1000), tensor(0.3000), 0.0, 0.5]\n",
      "[tensor(0.1000), tensor(0.3000), 0.0, 0.6]\n",
      "[tensor(0.1000), tensor(0.3000), 0.0, 0.7]\n",
      "[tensor(0.1000), tensor(0.3000), 0.0, 0.8]\n",
      "[tensor(0.1000), tensor(0.3000), 0.0, 0.9]\n",
      "[tensor(0.1000), tensor(0.3000), 0.1, 0.0]\n",
      "[tensor(0.1000), tensor(0.3000), 0.1, 0.1]\n",
      "[tensor(0.1000), tensor(0.3000), 0.1, 0.2]\n",
      "[tensor(0.1000), tensor(0.3000), 0.1, 0.3]\n",
      "[tensor(0.1000), tensor(0.3000), 0.1, 0.4]\n",
      "[tensor(0.1000), tensor(0.3000), 0.1, 0.5]\n",
      "[tensor(0.1000), tensor(0.3000), 0.1, 0.6]\n",
      "[tensor(0.1000), tensor(0.3000), 0.1, 0.7]\n",
      "[tensor(0.1000), tensor(0.3000), 0.1, 0.8]\n",
      "[tensor(0.1000), tensor(0.3000), 0.1, 0.9]\n",
      "[tensor(0.1000), tensor(0.3000), 0.2, 0.0]\n",
      "[tensor(0.1000), tensor(0.3000), 0.2, 0.1]\n",
      "[tensor(0.1000), tensor(0.3000), 0.2, 0.2]\n",
      "[tensor(0.1000), tensor(0.3000), 0.2, 0.3]\n",
      "[tensor(0.1000), tensor(0.3000), 0.2, 0.4]\n",
      "[tensor(0.1000), tensor(0.3000), 0.2, 0.5]\n",
      "[tensor(0.1000), tensor(0.3000), 0.2, 0.6]\n",
      "[tensor(0.1000), tensor(0.3000), 0.2, 0.7]\n",
      "[tensor(0.1000), tensor(0.3000), 0.2, 0.8]\n",
      "[tensor(0.1000), tensor(0.3000), 0.2, 0.9]\n",
      "[tensor(0.1000), tensor(0.3000), 0.3, 0.0]\n",
      "[tensor(0.1000), tensor(0.3000), 0.3, 0.1]\n",
      "[tensor(0.1000), tensor(0.3000), 0.3, 0.2]\n",
      "[tensor(0.1000), tensor(0.3000), 0.3, 0.3]\n",
      "[tensor(0.1000), tensor(0.3000), 0.3, 0.4]\n",
      "[tensor(0.1000), tensor(0.3000), 0.3, 0.5]\n",
      "[tensor(0.1000), tensor(0.3000), 0.3, 0.6]\n",
      "[tensor(0.1000), tensor(0.3000), 0.3, 0.7]\n",
      "[tensor(0.1000), tensor(0.3000), 0.3, 0.8]\n",
      "[tensor(0.1000), tensor(0.3000), 0.3, 0.9]\n",
      "[tensor(0.1000), tensor(0.3000), 0.4, 0.0]\n",
      "[tensor(0.1000), tensor(0.3000), 0.4, 0.1]\n",
      "[tensor(0.1000), tensor(0.3000), 0.4, 0.2]\n",
      "[tensor(0.1000), tensor(0.3000), 0.4, 0.3]\n",
      "[tensor(0.1000), tensor(0.3000), 0.4, 0.4]\n",
      "[tensor(0.1000), tensor(0.3000), 0.4, 0.5]\n",
      "[tensor(0.1000), tensor(0.3000), 0.4, 0.6]\n",
      "[tensor(0.1000), tensor(0.3000), 0.4, 0.7]\n",
      "[tensor(0.1000), tensor(0.3000), 0.4, 0.8]\n",
      "[tensor(0.1000), tensor(0.3000), 0.4, 0.9]\n",
      "[tensor(0.1000), tensor(0.3000), 0.5, 0.0]\n",
      "[tensor(0.1000), tensor(0.3000), 0.5, 0.1]\n",
      "[tensor(0.1000), tensor(0.3000), 0.5, 0.2]\n",
      "[tensor(0.1000), tensor(0.3000), 0.5, 0.3]\n",
      "[tensor(0.1000), tensor(0.3000), 0.5, 0.4]\n",
      "[tensor(0.1000), tensor(0.3000), 0.5, 0.5]\n",
      "[tensor(0.1000), tensor(0.3000), 0.5, 0.6]\n",
      "[tensor(0.1000), tensor(0.3000), 0.5, 0.7]\n",
      "[tensor(0.1000), tensor(0.3000), 0.5, 0.8]\n",
      "[tensor(0.1000), tensor(0.3000), 0.5, 0.9]\n",
      "[tensor(0.1000), tensor(0.3000), 0.6, 0.0]\n",
      "[tensor(0.1000), tensor(0.3000), 0.6, 0.1]\n",
      "[tensor(0.1000), tensor(0.3000), 0.6, 0.2]\n",
      "[tensor(0.1000), tensor(0.3000), 0.6, 0.3]\n",
      "[tensor(0.1000), tensor(0.3000), 0.6, 0.4]\n",
      "[tensor(0.1000), tensor(0.3000), 0.6, 0.5]\n",
      "[tensor(0.1000), tensor(0.3000), 0.6, 0.6]\n",
      "[tensor(0.1000), tensor(0.3000), 0.6, 0.7]\n",
      "[tensor(0.1000), tensor(0.3000), 0.6, 0.8]\n",
      "[tensor(0.1000), tensor(0.3000), 0.6, 0.9]\n",
      "[tensor(0.1000), tensor(0.3000), 0.7, 0.0]\n",
      "[tensor(0.1000), tensor(0.3000), 0.7, 0.1]\n",
      "[tensor(0.1000), tensor(0.3000), 0.7, 0.2]\n",
      "[tensor(0.1000), tensor(0.3000), 0.7, 0.3]\n",
      "[tensor(0.1000), tensor(0.3000), 0.7, 0.4]\n",
      "[tensor(0.1000), tensor(0.3000), 0.7, 0.5]\n",
      "[tensor(0.1000), tensor(0.3000), 0.7, 0.6]\n",
      "[tensor(0.1000), tensor(0.3000), 0.7, 0.7]\n",
      "[tensor(0.1000), tensor(0.3000), 0.7, 0.8]\n",
      "[tensor(0.1000), tensor(0.3000), 0.7, 0.9]\n",
      "[tensor(0.1000), tensor(0.3000), 0.8, 0.0]\n",
      "[tensor(0.1000), tensor(0.3000), 0.8, 0.1]\n",
      "[tensor(0.1000), tensor(0.3000), 0.8, 0.2]\n",
      "[tensor(0.1000), tensor(0.3000), 0.8, 0.3]\n",
      "[tensor(0.1000), tensor(0.3000), 0.8, 0.4]\n",
      "[tensor(0.1000), tensor(0.3000), 0.8, 0.5]\n",
      "[tensor(0.1000), tensor(0.3000), 0.8, 0.6]\n",
      "[tensor(0.1000), tensor(0.3000), 0.8, 0.7]\n",
      "[tensor(0.1000), tensor(0.3000), 0.8, 0.8]\n",
      "[tensor(0.1000), tensor(0.3000), 0.8, 0.9]\n",
      "[tensor(0.1000), tensor(0.3000), 0.9, 0.0]\n",
      "[tensor(0.1000), tensor(0.3000), 0.9, 0.1]\n",
      "[tensor(0.1000), tensor(0.3000), 0.9, 0.2]\n",
      "[tensor(0.1000), tensor(0.3000), 0.9, 0.3]\n",
      "[tensor(0.1000), tensor(0.3000), 0.9, 0.4]\n",
      "[tensor(0.1000), tensor(0.3000), 0.9, 0.5]\n",
      "[tensor(0.1000), tensor(0.3000), 0.9, 0.6]\n",
      "[tensor(0.1000), tensor(0.3000), 0.9, 0.7]\n",
      "[tensor(0.1000), tensor(0.3000), 0.9, 0.8]\n",
      "[tensor(0.1000), tensor(0.3000), 0.9, 0.9]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL4AAAC+CAYAAACLdLWdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAElElEQVR4nO3dT2scBRjH8SepijE1IF4qYoRKrIiKIFiPnn0rFTx79uAb0FfhK2mPHoS2IlJQKhQvNv5P1sNsKBRiB+bZ2Wl+n8+lhF2eHZZvptNNns7OarVaFYTZ3fYBwDYIn0jCJ5LwiSR8IgmfSMInkvCJJHwiPTP6mZ/sTH+1d6aPqHcbZry9kBl77zUMub6QGR80zHi/YcY4zvhEEj6RhE8k4RNJ+EQSPpGETyThE0n4RBI+kYRPJOETSfhEEj6RhE8k4RNp/CLKjw2v9mLDjIOGGc8vZMbRt9NnPDd9RI9/G2b82TDjo1HPcsYnkvCJNP5SJ8W9qrpZVcdVtV/DOurhVo+IDRD+mftV9VVV3anh78GdqlpV1TdVda2qblTVla0dHc1c6lQN0X9eVd+vvz6tqpP1n1VVd9eP35//0NgM4VcNZ/o/6lHojztdP/71bEfEhgn/Xg2XN+dFf+a0qm6vn89TT/g3a/y7sFtVtzZ4LMxG+Mc1/EN2jJ2qerjBY2E2wt+v4dObMVZVdXmDx8JshH+9nnx9f+a0qj7c4LEwG+EfVtWb9eR3YreGz/P9MOtCEH5V1adVtVfnvxu768dvzHZEbJjwq4afyH5ZVUfrr3er6lI9eneO1o/7ye2F4VcWzlypqi9q+Jz+Vg2f3lyu4Zre5c2FI/zHHZbQA4wP/4eGV9tvmNGxAPLsQmZ0XGi+sZRllo4lEososFHCJ5LwiSR8IgmfSMInkvCJJHwiCZ9IwieS8IkkfCIJn0jCJ5LwiSR8Io1eRPnpr+kv9mrHMstS7mbSccq41DBj7H+N8n+uNiyz7C1lEeWzUc9yxieS8IkkfCIJn0jCJ5LwiSR8IgmfSMInkvCJJHwiCZ9IwieS8IkkfCIJn0ijF1E6dkhe+HX6jJfuTp/RcjeTpThpmPFPw4yrd6bPOJjvtvHO+EQSPpGETyThE0n4RBI+kYRPJOETSfhEEj6RhE8k4RNJ+EQSPpGETyThE2nWRZSOG5Fc+2X6jIOOO5F06Fgi6bgjSseNSP5umPHaz9NnvDLuac74RBI+kYRPJOETSfhEEj6RhE8k4RNJ+EQSPpGETyThE0n4RBI+kYRPJOETafQiylJuRNLxnfpWw77D/vQRPXci6ZjRsYjSMeP3hhkWUeB8wieS8IkkfCIJn0jCJ5LwiSR8IgmfSMInkvCJJHwiCZ9IwieS8IkkfCLNuoiylBuRdDhqWGY56LiLSMeMjiWS44YZHYsoH497mjM+kYRPJOETSfhEEj6RhE8k4RNJ+EQSPpGETyThE0n4RBI+kYRPJOETSfhEGr2IcrvhxToWUZbyndpxI5KjB9NnvLyUO5F0LKL81jBjpKV0BLMSPpGETyThE0n4RBI+kYRPJOETSfhEEj6RhE8k4RNJ+EQSPpGETyThE2nWO6J0fJedNMzoWCJZyozXH06fcfjd9BkWUeApIHwiCZ9IwieS8IkkfCIJn0jCJ5LwiSR8IgmfSMInkvCJJHwiCZ9IwifSzmq1Wm37IGBuzvhEEj6RhE8k4RNJ+EQSPpGETyThE0n4RPoP3xdvBoaKvmIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52 0.52 0.52 0.52 0.53 0.53 0.53 0.53 0.53 0.53 \n",
      "0.52 0.52 0.52 0.52 0.53 0.53 0.53 0.53 0.53 0.53 \n",
      "0.52 0.52 0.52 0.52 0.52 0.53 0.53 0.53 0.53 0.53 \n",
      "0.52 0.52 0.52 0.52 0.52 0.52 0.53 0.53 0.53 0.53 \n",
      "0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.53 0.53 \n",
      "0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.53 \n",
      "0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 \n",
      "0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 \n",
      "0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 \n",
      "0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 0.52 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.7.16/envs/bcirl2/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argmax() got an unexpected keyword argument 'axis'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1167818/1574799898.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Call method specific update function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mupdater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_td\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SnakeBcIRL/imitation_learning/bcirl.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, policy, rollouts, logger, envs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                             \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                         \u001b[0mnext_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"action\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0mtd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"next_observation\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_obs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1167818/1711999369.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         return_value = (torch.tensor([step[0].tolist() for step in steps],dtype=torch.float32),\n\u001b[1;32m     16\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1167818/1711999369.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         return_value = (torch.tensor([step[0].tolist() for step in steps],dtype=torch.float32),\n\u001b[1;32m     16\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SnakeBcIRL/snake_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Change snake direction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_direction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Move snake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SnakeBcIRL/snake.py\u001b[0m in \u001b[0;36mchange_direction\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchange_direction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.16/envs/bcirl2/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \"\"\"\n\u001b[0;32m-> 1195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.16/envs/bcirl2/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Call _wrapit from within the except clause to ensure a potential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# exception has a traceback chain.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.16/envs/bcirl2/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.16/envs/bcirl2/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[0;34m(self, array)\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_wrap__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             )\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m             \u001b[0;31m# Workaround, torch has no built-in bool tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Storage for the rollouts\n",
    "obs = envs.reset()\n",
    "td = TensorDict({\"observation\": obs}, batch_size=[cfg.num_envs])\n",
    "# Storage for the rollouts\n",
    "storage_td = TensorDict({}, batch_size=[cfg.num_envs, cfg.num_steps], device=device)\n",
    "\n",
    "for update_i in range(start_update, num_updates):\n",
    "    is_last_update = update_i == num_updates - 1\n",
    "    for step_idx in range(cfg.num_steps):\n",
    "        # Collect experience.\n",
    "        with torch.no_grad():\n",
    "            policy.act(td)\n",
    "        next_obs, reward, done, infos = envs.step(td[\"action\"])\n",
    "\n",
    "        td[\"next_observation\"] = next_obs\n",
    "        for env_i, info in enumerate(infos):\n",
    "            if \"final_obs\" in info:\n",
    "                td[\"next_observation\"][env_i] = info[\"final_obs\"]\n",
    "        td[\"reward\"] = reward.reshape(-1, 1)\n",
    "        td[\"done\"] = done\n",
    "    \n",
    "        storage_td[:, step_idx] = td\n",
    "\n",
    "        # Log to CLI/wandb.\n",
    "        logger.collect_env_step_info(infos)\n",
    "    \n",
    "    # Call method specific update function\n",
    "    updater.update(policy, storage_td, logger, envs=envs)\n",
    "\n",
    "\n",
    "\n",
    "    if cfg.log_interval != -1 and (\n",
    "        update_i % cfg.log_interval == 0 or is_last_update\n",
    "    ):\n",
    "        logger.interval_log(update_i, steps_per_update * (update_i + 1))\n",
    "        eval_env = SnakeEnv(cfg.env.env_settings.params.config)\n",
    "        reward_map = np.zeros((eval_env.screen_width//eval_env.block_size, eval_env.screen_height//eval_env.block_size))\n",
    "        apple_pos = eval_env.reset()[0][:2]\n",
    "        #test what you got so far by plotting a heat map of the reward using the snake only \n",
    "        for x in range(eval_env.screen_width//eval_env.block_size):\n",
    "            for y in range(eval_env.screen_height//eval_env.block_size ):\n",
    "                x_grid = x * eval_env.block_size / eval_env.screen_width\n",
    "                y_grid = y * eval_env.block_size / eval_env.screen_height\n",
    "                print([*apple_pos,x_grid,y_grid])\n",
    "                reward_map[x,y] = updater.reward(next_obs = torch.tensor([*apple_pos,x_grid,y_grid]+[0]*(eval_env.observation_space.shape[0]-3),dtype=torch.float32).to(device).view(1,1,-1))\n",
    "        fig, ax = plt.subplots(figsize=(2, 2))  # Adjust the figsize as desired\n",
    "\n",
    "        # Plot the reward map without axis and numbers\n",
    "        image = ax.imshow(reward_map, cmap='hot', interpolation='nearest')\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Plot the apple\n",
    "        ax.scatter(\n",
    "            apple_pos[1] * eval_env.screen_height // eval_env.block_size,\n",
    "            apple_pos[0] * eval_env.screen_width // eval_env.block_size,\n",
    "            c='red',\n",
    "            s=60\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        #pretty print the reward map\n",
    "        for x in range(eval_env.screen_width//eval_env.block_size):\n",
    "            for y in range(eval_env.screen_height//eval_env.block_size ):\n",
    "                print(f\"{reward_map[x,y]:.2f}\", end=\" \")\n",
    "            print()\n",
    "\n",
    "    if cfg.save_interval != -1 and (\n",
    "        (update_i + 1) % cfg.save_interval == 0 or is_last_update\n",
    "    ):\n",
    "        save_name = osp.join(logger.save_path, f\"ckpt.{update_i}.pth\")\n",
    "        torch.save(\n",
    "            {\n",
    "                \"policy\": policy.state_dict(),\n",
    "                \"updater\": updater.state_dict(),\n",
    "                \"update_i\": update_i,\n",
    "            },\n",
    "            save_name,\n",
    "        )\n",
    "        print(f\"Saved to {save_name}\")\n",
    "        eval_info[\"last_ckpt\"] = save_name\n",
    "\n",
    "logger.close()\n",
    "print(eval_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(save_name)\n",
    "updater.load_state_dict(ckpt[\"updater\"], should_load_opt=cfg.resume_training)\n",
    "policy.load_state_dict(ckpt[\"policy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.env.env_settings.params.config[\"render_mode\"] = \"human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "envs = vectorized_env([SnakeEnv(cfg.env.env_settings.params.config) for _ in range(1)])\n",
    "while True:\n",
    "\n",
    "    obs = envs.reset()\n",
    "    td = TensorDict({\"observation\": obs}, batch_size=[1])\n",
    "    done = False \n",
    "    while not done : \n",
    "        with torch.no_grad():\n",
    "            policy.act(td)\n",
    "        next_obs, reward, done, infos = envs.step(td[\"action\"])\n",
    "        envs.render(mode=\"human\")\n",
    "        td[\"next_observation\"] = next_obs\n",
    "        td[\"reward\"] = reward.reshape(-1, 1)\n",
    "\n",
    "        td[\"done\"] = done\n",
    "\n",
    "        td[\"observation\"] = next_obs\n",
    "        # Log to CLI/wandb.\n",
    "        logger.collect_env_step_info(infos)\n",
    "        pygame.time.wait(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcirl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
